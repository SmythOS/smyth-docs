# LLM Assistant

The `LLM Assistant` is designed to handle chat conversations, tracking and remembering the conversation flow. It's perfect for agents who need consistent and coherent interactions with users.

> 📝 **Note:** We provide the model for you without any configuration required [Account Management - Model Rates](../../../account-management/model-rates), and the flexibility to bring your own model.

<Arcade  src="https://demo.arcade.software/feB8bIw53rxIILXr2QwP?embed&embed_mobile=tab&embed_desktop=inline&show_copy_link=true" title="LLM Assistant | SmythOS" />

---

## Settings

### Model
Ensure the correct model is configured. By default, OpenAI models are used.
> 💡 `SmythOS` also supports Claude AI and Together AI models. To learn more, check out the [Global Keys Management documentation](https://app.smythos.com/doc/#/vault/keysManagement?id=global-keys).

### ✨ Custom Models
You can create custom Large Language Models (LLMs):
1. **Custom Model Button**: Click to start creating a new model.
2. **Fill Required Fields**:
   - **Name**: Unique name for the custom model.
   - **Features**: Currently, only text completion.
   - **Provider**: Choose between Amazon's Bedrock or Google's Vertex AI.
3. **Next Step**:
   - **Foundation Model**: Varies based on the provider.
   - **Credentials**:
     - **Vertex AI**: Google credentials and Project ID.
     - **Bedrock**: Key ID and Secret Key.
4. **Create Model**: Click **Create** after setting fields. Optional settings like Context Window and Max Output Tokens depend on the model.
5. **Manage Models**: Each custom model has a **Delete** button to remove it.

> 🏢 Custom models are an enterprise feature. [Contact us](https://smythos.com/contact-us/) to get access.

### Behavior
The `Behavior` field determines how the assistant will act. Default value:
> You are a helpful assistant that helps people with their questions

### ⚙️ Advanced Settings
- **🔀 Passthrough Mode**: Controls streaming behavior
  - When disabled (default): The assistant automatically streams all responses
  - When enabled: Gives you manual control over what content gets streamed to users
  - Use this feature when you need to process assistant outputs before showing them to users or when implementing custom streaming logic in complex workflows

---

## Inputs

- `UserId` and `ConversationId`:
  - Used to uniquely identify conversations.
  - Initially optional but can be adjusted.
  - IDs must be distinct.

- `UserInput`:
  - Mandatory by default.
  - Captures user interactions with the `LLM Assistant`.

---

## Outputs

The `LLM Assistant` generates a single output:

- **Response**: Contains the rendered output generated by the assistant.